{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab4d904",
   "metadata": {},
   "source": [
    "# Swift Assignment Summary: Transit Performance Analysis\n",
    "\n",
    "This project analyzes shipment tracking data from a courier logistics network to evaluate transit performance, operational efficiency, and delivery accuracy.\n",
    "The dataset, provided in nested JSON format, contains detailed shipment and event-level tracking information (including facility movements, timestamps, and delivery milestones).\n",
    "\n",
    "## Objective\n",
    "\n",
    "To extract, process, and analyze courier shipment data to compute key logistics performance indicators such as:\n",
    "\n",
    "Total transit time, facility touchpoints, and inter-facility movement efficiency\n",
    "\n",
    "Average transit velocity and service-type comparison\n",
    "\n",
    "Delivery success metrics (first-attempt delivery rates, out-for-delivery attempts)\n",
    "\n",
    "## Approach\n",
    "\n",
    "The analysis was performed in six structured phases:\n",
    "\n",
    "- Data Loading & Exploration:\n",
    "Loaded and inspected the hierarchical JSON data structure to identify key shipment and event attributes.\n",
    "\n",
    "- Data Flattening:\n",
    "Extracted shipment-level and event-level details into a structured tabular DataFrame for analysis.\n",
    "\n",
    "- Transit Metric Computation:\n",
    "Calculated per-shipment performance metrics — including total transit hours, facility visits, inter-facility transit time, and delivery attempts.\n",
    "\n",
    "- Edge Case Handling:\n",
    "Implemented robust handling for missing fields, inconsistent timestamps ($numberLong vs ISO), null addresses, empty event arrays, and duplicate timestamps.\n",
    "\n",
    "- Detailed Output Generation:\n",
    "Exported a clean, shipment-level dataset (transit_performance_detailed.csv) with all computed metrics standardized and timestamped in IST.\n",
    "\n",
    "- Network Summary Analysis:\n",
    "Produced an aggregated summary file (transit_performance_summary.csv) capturing overall network trends, facility utilization, service-type comparison, and delivery performance statistics.\n",
    "\n",
    "## Outcome\n",
    "\n",
    "The final outputs enable a clear view of courier network performance:\n",
    "\n",
    "- Average transit time: ~94 hours (≈3.9 days)\n",
    "\n",
    "- Average facilities per shipment: 2.8\n",
    "\n",
    "- First-attempt delivery rate: ~85%\n",
    "\n",
    "- Service analyzed: FedEx Express Saver\n",
    "\n",
    "This end-to-end analysis provides actionable insights into shipment flow efficiency, delivery accuracy, and potential bottlenecks in transit operations — forming the foundation for data-driven logistics optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080b6a2",
   "metadata": {},
   "source": [
    "## Part 1: Load and Explore Data \n",
    "### Objective:\n",
    "Load the given JSON shipment tracking data, inspect its structure,\n",
    "and perform basic exploration to understand key fields and hierarchy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09728caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of root object: <class 'list'>\n",
      "Number of records in JSON: 99\n",
      "\n",
      "Keys in first record:\n",
      " dict_keys(['highestSeverity', 'notifications', 'duplicateWaybill', 'moreData', 'trackDetailsCount', 'trackDetails'])\n",
      "\n",
      "Number of track details in first record: 1\n",
      "\n",
      "Keys inside 'trackDetails[0]':\n",
      "dict_keys(['notification', 'trackingNumber', 'trackingNumberUniqueIdentifier', 'statusDetail', 'informationNotes', 'customerExceptionRequests', 'carrierCode', 'operatingCompanyOrCarrierDescription', 'otherIdentifiers', 'service', 'packageWeight', 'shipmentWeight', 'packaging', 'packageSequenceNumber', 'packageCount', 'shipmentContentPieceCount', 'packageContentPieceCount', 'creatorSoftwareId', 'charges', 'attributes', 'shipmentContents', 'packageContents', 'commodities', 'customsOptionDetails', 'specialHandlings', 'payments', 'shipperAddress', 'datesOrTimes', 'specialInstructions', 'lastUpdatedDestinationAddress', 'destinationAddress', 'actualDeliveryAddress', 'deliveryLocationType', 'deliveryLocationDescription', 'deliveryAttempts', 'deliverySignatureName', 'pieceCountVerificationDetails', 'totalUniqueAddressCountInConsolidation', 'availableImages', 'notificationEventsAvailable', 'splitShipmentParts', 'deliveryOptionEligibilityDetails', 'events'])\n",
      "\n",
      "Tracking Number: 391128701026\n",
      "Service Info: {'type': 'FEDEX_EXPRESS_SAVER', 'description': 'FedEx Economy', 'shortDescription': 'XS'}\n",
      "Origin City: Bangalore\n",
      "Destination City: Gurgaon\n",
      "\n",
      "Number of events: 11\n",
      "Sample event keys: dict_keys(['timestamp', 'eventType', 'eventDescription', 'statusExceptionCode', 'statusExceptionDescription', 'address', 'arrivalLocation'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define the path to the dataset\n",
    "\n",
    "file_path = \"C:/Users/Alok verma/Downloads/Swift Assignment 4 - Dataset (2).json\"\n",
    "\n",
    "# Step 2: Load the JSON data\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Step 3: Quick inspection\n",
    "\n",
    "print(f\"Type of root object: {type(data)}\")\n",
    "print(f\"Number of records in JSON: {len(data)}\\n\")\n",
    "\n",
    "# Step 4: Explore the first record to understand the structure\n",
    "\n",
    "first_record = data[0]\n",
    "print(\"Keys in first record:\\n\", first_record.keys())\n",
    "\n",
    "# Step 5: Drill down to 'trackDetails' — this usually holds shipment details\n",
    "\n",
    "if 'trackDetails' in first_record:\n",
    "    print(\"\\nNumber of track details in first record:\", len(first_record['trackDetails']))\n",
    "    if len(first_record['trackDetails']) > 0:\n",
    "        print(\"\\nKeys inside 'trackDetails[0]':\")\n",
    "        print(first_record['trackDetails'][0].keys())\n",
    "\n",
    "# Step 6: Explore nested fields within trackDetails\n",
    "\n",
    "sample_detail = first_record['trackDetails'][0]\n",
    "print(\"\\nTracking Number:\", sample_detail.get('trackingNumber'))\n",
    "print(\"Service Info:\", sample_detail.get('service', {}))\n",
    "print(\"Origin City:\", sample_detail.get('shipperAddress', {}).get('city'))\n",
    "print(\"Destination City:\", sample_detail.get('destinationAddress', {}).get('city'))\n",
    "\n",
    "# Step 7: Check structure of 'events' array (important for transit performance)\n",
    "\n",
    "events = sample_detail.get('events', [])\n",
    "print(f\"\\nNumber of events: {len(events)}\")\n",
    "if len(events) > 0:\n",
    "    print(\"Sample event keys:\", events[0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09166031",
   "metadata": {},
   "source": [
    "## Part 2: Flatten and Extract Transit Data\n",
    "### Objective:\n",
    "Extract and flatten shipment-level and event-level details from the nested JSON\n",
    "structure for each shipment record into a tabular (DataFrame) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ab55bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening complete! Extracted 1240 event records across shipments.\n",
      "\n",
      "Preview of flattened data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracking_number</th>\n",
       "      <th>service_type</th>\n",
       "      <th>service_description</th>\n",
       "      <th>carrier_code</th>\n",
       "      <th>package_weight_value</th>\n",
       "      <th>package_weight_units</th>\n",
       "      <th>packaging_type</th>\n",
       "      <th>origin_city</th>\n",
       "      <th>origin_state</th>\n",
       "      <th>origin_pincode</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>destination_state</th>\n",
       "      <th>destination_pincode</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>event_description</th>\n",
       "      <th>event_location_city</th>\n",
       "      <th>event_location_state</th>\n",
       "      <th>event_location_postal_code</th>\n",
       "      <th>arrival_location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>2020-03-20 13:37:00</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>122001</td>\n",
       "      <td>DELIVERY_LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>OD</td>\n",
       "      <td>2020-03-20 10:16:00</td>\n",
       "      <td>On FedEx vehicle for delivery</td>\n",
       "      <td>MANESAR</td>\n",
       "      <td>HR</td>\n",
       "      <td>122050</td>\n",
       "      <td>VEHICLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-03-20 09:18:00</td>\n",
       "      <td>In transit</td>\n",
       "      <td>GURGAON</td>\n",
       "      <td>HR</td>\n",
       "      <td>122001</td>\n",
       "      <td>FEDEX_FACILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>AR</td>\n",
       "      <td>2020-03-20 08:46:00</td>\n",
       "      <td>At local FedEx facility</td>\n",
       "      <td>MANESAR</td>\n",
       "      <td>HR</td>\n",
       "      <td>122050</td>\n",
       "      <td>DESTINATION_FEDEX_FACILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-03-20 01:04:00</td>\n",
       "      <td>In transit</td>\n",
       "      <td>GURGAON</td>\n",
       "      <td>HR</td>\n",
       "      <td>122001</td>\n",
       "      <td>FEDEX_FACILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-03-19 23:15:00</td>\n",
       "      <td>In transit</td>\n",
       "      <td>GURGAON</td>\n",
       "      <td>HR</td>\n",
       "      <td>122001</td>\n",
       "      <td>FEDEX_FACILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-03-17 04:33:00</td>\n",
       "      <td>In transit</td>\n",
       "      <td>BANGALORE</td>\n",
       "      <td>KA</td>\n",
       "      <td>562123</td>\n",
       "      <td>FEDEX_FACILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-03-17 00:06:00</td>\n",
       "      <td>In transit</td>\n",
       "      <td>BANGALORE</td>\n",
       "      <td>KA</td>\n",
       "      <td>562123</td>\n",
       "      <td>FEDEX_FACILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>DP</td>\n",
       "      <td>2020-03-16 22:54:00</td>\n",
       "      <td>Left FedEx origin facility</td>\n",
       "      <td>BANGALORE</td>\n",
       "      <td>KA</td>\n",
       "      <td>560048</td>\n",
       "      <td>ORIGIN_FEDEX_FACILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>391128701026</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FedEx Economy</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>YOUR_PACKAGING</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>KA</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HR</td>\n",
       "      <td>None</td>\n",
       "      <td>PU</td>\n",
       "      <td>2020-03-16 15:44:00</td>\n",
       "      <td>Picked up</td>\n",
       "      <td>BANGALORE</td>\n",
       "      <td>KA</td>\n",
       "      <td>560048</td>\n",
       "      <td>PICKUP_LOCATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tracking_number         service_type service_description carrier_code  \\\n",
       "0    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "1    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "2    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "3    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "4    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "5    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "6    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "7    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "8    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "9    391128701026  FEDEX_EXPRESS_SAVER       FedEx Economy         FDXE   \n",
       "\n",
       "   package_weight_value package_weight_units  packaging_type origin_city  \\\n",
       "0                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "1                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "2                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "3                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "4                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "5                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "6                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "7                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "8                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "9                  14.0                   KG  YOUR_PACKAGING   Bangalore   \n",
       "\n",
       "  origin_state origin_pincode destination_city destination_state  \\\n",
       "0           KA           None          Gurgaon                HR   \n",
       "1           KA           None          Gurgaon                HR   \n",
       "2           KA           None          Gurgaon                HR   \n",
       "3           KA           None          Gurgaon                HR   \n",
       "4           KA           None          Gurgaon                HR   \n",
       "5           KA           None          Gurgaon                HR   \n",
       "6           KA           None          Gurgaon                HR   \n",
       "7           KA           None          Gurgaon                HR   \n",
       "8           KA           None          Gurgaon                HR   \n",
       "9           KA           None          Gurgaon                HR   \n",
       "\n",
       "  destination_pincode event_type     event_timestamp  \\\n",
       "0                None         DL 2020-03-20 13:37:00   \n",
       "1                None         OD 2020-03-20 10:16:00   \n",
       "2                None         IT 2020-03-20 09:18:00   \n",
       "3                None         AR 2020-03-20 08:46:00   \n",
       "4                None         IT 2020-03-20 01:04:00   \n",
       "5                None         IT 2020-03-19 23:15:00   \n",
       "6                None         IT 2020-03-17 04:33:00   \n",
       "7                None         IT 2020-03-17 00:06:00   \n",
       "8                None         DP 2020-03-16 22:54:00   \n",
       "9                None         PU 2020-03-16 15:44:00   \n",
       "\n",
       "               event_description event_location_city event_location_state  \\\n",
       "0                      Delivered             Gurgaon                   HR   \n",
       "1  On FedEx vehicle for delivery             MANESAR                   HR   \n",
       "2                     In transit             GURGAON                   HR   \n",
       "3        At local FedEx facility             MANESAR                   HR   \n",
       "4                     In transit             GURGAON                   HR   \n",
       "5                     In transit             GURGAON                   HR   \n",
       "6                     In transit           BANGALORE                   KA   \n",
       "7                     In transit           BANGALORE                   KA   \n",
       "8     Left FedEx origin facility           BANGALORE                   KA   \n",
       "9                      Picked up           BANGALORE                   KA   \n",
       "\n",
       "  event_location_postal_code       arrival_location_type  \n",
       "0                     122001           DELIVERY_LOCATION  \n",
       "1                     122050                     VEHICLE  \n",
       "2                     122001              FEDEX_FACILITY  \n",
       "3                     122050  DESTINATION_FEDEX_FACILITY  \n",
       "4                     122001              FEDEX_FACILITY  \n",
       "5                     122001              FEDEX_FACILITY  \n",
       "6                     562123              FEDEX_FACILITY  \n",
       "7                     562123              FEDEX_FACILITY  \n",
       "8                     560048       ORIGIN_FEDEX_FACILITY  \n",
       "9                     560048             PICKUP_LOCATION  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1240 entries, 0 to 1239\n",
      "Data columns (total 20 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   tracking_number             1240 non-null   object        \n",
      " 1   service_type                1240 non-null   object        \n",
      " 2   service_description         1240 non-null   object        \n",
      " 3   carrier_code                1240 non-null   object        \n",
      " 4   package_weight_value        1240 non-null   float64       \n",
      " 5   package_weight_units        1240 non-null   object        \n",
      " 6   packaging_type              1240 non-null   object        \n",
      " 7   origin_city                 1240 non-null   object        \n",
      " 8   origin_state                1240 non-null   object        \n",
      " 9   origin_pincode              0 non-null      object        \n",
      " 10  destination_city            1240 non-null   object        \n",
      " 11  destination_state           1240 non-null   object        \n",
      " 12  destination_pincode         0 non-null      object        \n",
      " 13  event_type                  1240 non-null   object        \n",
      " 14  event_timestamp             1240 non-null   datetime64[ns]\n",
      " 15  event_description           1240 non-null   object        \n",
      " 16  event_location_city         1141 non-null   object        \n",
      " 17  event_location_state        1141 non-null   object        \n",
      " 18  event_location_postal_code  1141 non-null   object        \n",
      " 19  arrival_location_type       1240 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(18)\n",
      "memory usage: 193.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define a helper function to safely extract nested fields\n",
    "\n",
    "def get_value(data_dict, key_path, default=None):\n",
    "    \"\"\"Safely extract nested values using a list of keys.\"\"\"\n",
    "    current = data_dict\n",
    "    for key in key_path:\n",
    "        if isinstance(current, dict) and key in current:\n",
    "            current = current[key]\n",
    "        else:\n",
    "            return default\n",
    "    return current\n",
    "\n",
    "# Create an empty list to store flattened records\n",
    "\n",
    "\n",
    "flattened_records = []\n",
    "\n",
    "# Iterate through all top-level records\n",
    "for record in data:\n",
    "    track_details_list = record.get(\"trackDetails\", [])\n",
    "    if not track_details_list:\n",
    "        continue  \n",
    "    \n",
    "    # Loop through each shipment inside 'trackDetails'\n",
    "    \n",
    "    for shipment in track_details_list:\n",
    "        tracking_number = shipment.get(\"trackingNumber\")\n",
    "        service_type = get_value(shipment, [\"service\", \"type\"])\n",
    "        service_description = get_value(shipment, [\"service\", \"description\"])\n",
    "        carrier_code = shipment.get(\"carrierCode\")\n",
    "        \n",
    "        # Weight & packaging\n",
    "        weight_value = get_value(shipment, [\"packageWeight\", \"value\"])\n",
    "        weight_units = get_value(shipment, [\"packageWeight\", \"units\"])\n",
    "        packaging_type = get_value(shipment, [\"packaging\", \"type\"])\n",
    "        \n",
    "        # Origin (shipper address)\n",
    "        origin_city = get_value(shipment, [\"shipperAddress\", \"city\"])\n",
    "        origin_state = get_value(shipment, [\"shipperAddress\", \"stateOrProvinceCode\"])\n",
    "        origin_pincode = get_value(shipment, [\"shipperAddress\", \"postalCode\"])\n",
    "        \n",
    "        # Destination address\n",
    "        destination_city = get_value(shipment, [\"destinationAddress\", \"city\"])\n",
    "        destination_state = get_value(shipment, [\"destinationAddress\", \"stateOrProvinceCode\"])\n",
    "        destination_pincode = get_value(shipment, [\"destinationAddress\", \"postalCode\"])\n",
    "        \n",
    "        # Extract events array\n",
    "        events = shipment.get(\"events\", [])\n",
    "        \n",
    "        if not events:\n",
    "            # Create at least one record even if events missing\n",
    "            flattened_records.append({\n",
    "                \"tracking_number\": tracking_number,\n",
    "                \"service_type\": service_type,\n",
    "                \"service_description\": service_description,\n",
    "                \"carrier_code\": carrier_code,\n",
    "                \"package_weight_value\": weight_value,\n",
    "                \"package_weight_units\": weight_units,\n",
    "                \"packaging_type\": packaging_type,\n",
    "                \"origin_city\": origin_city,\n",
    "                \"origin_state\": origin_state,\n",
    "                \"origin_pincode\": origin_pincode,\n",
    "                \"destination_city\": destination_city,\n",
    "                \"destination_state\": destination_state,\n",
    "                \"destination_pincode\": destination_pincode,\n",
    "                \"event_type\": None,\n",
    "                \"event_timestamp\": None,\n",
    "                \"event_description\": None,\n",
    "                \"event_location_city\": None,\n",
    "                \"event_location_state\": None,\n",
    "                \"event_location_postal_code\": None,\n",
    "                \"arrival_location_type\": None\n",
    "            })\n",
    "        else:\n",
    "            # For each event inside shipment\n",
    "            for event in events:\n",
    "                # Handle timestamp that could be in $numberLong or ISO format\n",
    "                raw_timestamp = event.get(\"timestamp\")\n",
    "                if isinstance(raw_timestamp, dict) and \"$numberLong\" in raw_timestamp:\n",
    "                    try:\n",
    "                        event_timestamp = datetime.fromtimestamp(int(raw_timestamp[\"$numberLong\"]) / 1000)\n",
    "                    except Exception:\n",
    "                        event_timestamp = None\n",
    "                else:\n",
    "                    event_timestamp = pd.to_datetime(raw_timestamp, errors='coerce')\n",
    "\n",
    "                flattened_records.append({\n",
    "                    \"tracking_number\": tracking_number,\n",
    "                    \"service_type\": service_type,\n",
    "                    \"service_description\": service_description,\n",
    "                    \"carrier_code\": carrier_code,\n",
    "                    \"package_weight_value\": weight_value,\n",
    "                    \"package_weight_units\": weight_units,\n",
    "                    \"packaging_type\": packaging_type,\n",
    "                    \"origin_city\": origin_city,\n",
    "                    \"origin_state\": origin_state,\n",
    "                    \"origin_pincode\": origin_pincode,\n",
    "                    \"destination_city\": destination_city,\n",
    "                    \"destination_state\": destination_state,\n",
    "                    \"destination_pincode\": destination_pincode,\n",
    "                    \"event_type\": event.get(\"eventType\"),\n",
    "                    \"event_timestamp\": event_timestamp,\n",
    "                    \"event_description\": event.get(\"eventDescription\"),\n",
    "                    \"event_location_city\": get_value(event, [\"address\", \"city\"]),\n",
    "                    \"event_location_state\": get_value(event, [\"address\", \"stateOrProvinceCode\"]),\n",
    "                    \"event_location_postal_code\": get_value(event, [\"address\", \"postalCode\"]),\n",
    "                    \"arrival_location_type\": event.get(\"arrivalLocation\")\n",
    "                })\n",
    "\n",
    "# Convert the flattened list into a DataFrame\n",
    "df_transit = pd.DataFrame(flattened_records)\n",
    "\n",
    "# Display basic summary\n",
    "print(f\"Flattening complete! Extracted {len(df_transit)} event records across shipments.\\n\")\n",
    "print(\"Preview of flattened data:\")\n",
    "display(df_transit.head(10))\n",
    "\n",
    "# Quick info summary\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df_transit.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138c1d1",
   "metadata": {},
   "source": [
    "## Part 3: Compute Transit Performance Metrics\n",
    "\n",
    "Preconditions:\n",
    "- `data` : the loaded JSON list (root)\n",
    "- `df_transit` : flattened DataFrame from Part 2 (one row per event)\n",
    "If you don't have df_transit, re-run Part 2 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dbc33c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique event types in dataset: ['AF', 'AR', 'AS', 'DE', 'DL', 'DP', 'IT', 'OC', 'OD', 'PU', 'SE']\n",
      "Computation complete. Per-shipment metrics generated for 99 shipments.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracking_number</th>\n",
       "      <th>service_type</th>\n",
       "      <th>carrier_code</th>\n",
       "      <th>package_weight_value</th>\n",
       "      <th>package_weight_units</th>\n",
       "      <th>origin_city</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>pickup_datetime_ist</th>\n",
       "      <th>delivery_datetime_ist</th>\n",
       "      <th>total_transit_hours</th>\n",
       "      <th>num_facilities_visited</th>\n",
       "      <th>num_in_transit_events</th>\n",
       "      <th>time_in_inter_facility_transit_hours</th>\n",
       "      <th>avg_hours_per_facility</th>\n",
       "      <th>is_express_service</th>\n",
       "      <th>delivery_location_type</th>\n",
       "      <th>num_out_for_delivery_attempts</th>\n",
       "      <th>first_attempt_delivery</th>\n",
       "      <th>total_events_count</th>\n",
       "      <th>event_type_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280267328981</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2021-06-11 18:56:00+05:30</td>\n",
       "      <td>2021-06-18 17:18:00+05:30</td>\n",
       "      <td>166.366667</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>155.633333</td>\n",
       "      <td>55.455556</td>\n",
       "      <td>True</td>\n",
       "      <td>IN_BOND_OR_CAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>{'IT': 9, 'AR': 2, 'OC': 1, 'PU': 1, 'DP': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280267329094</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Noida</td>\n",
       "      <td>2021-06-11 18:56:00+05:30</td>\n",
       "      <td>2021-06-16 11:28:00+05:30</td>\n",
       "      <td>112.533333</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>107.550000</td>\n",
       "      <td>37.511111</td>\n",
       "      <td>True</td>\n",
       "      <td>RECEPTIONIST_OR_FRONT_DESK</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>{'IT': 7, 'AR': 4, 'DE': 2, 'OC': 1, 'PU': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280307632740</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2021-06-14 19:31:00+05:30</td>\n",
       "      <td>2021-06-16 16:30:00+05:30</td>\n",
       "      <td>44.983333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>38.133333</td>\n",
       "      <td>14.994444</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>{'IT': 4, 'OC': 1, 'PU': 1, 'DP': 1, 'AF': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280307633276</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2021-06-14 19:31:00+05:30</td>\n",
       "      <td>2021-06-16 16:30:00+05:30</td>\n",
       "      <td>44.983333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>38.166667</td>\n",
       "      <td>14.994444</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>{'IT': 4, 'OC': 1, 'PU': 1, 'DP': 1, 'AF': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>280439181099</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>32.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2021-06-16 19:22:00+05:30</td>\n",
       "      <td>2021-06-24 18:22:00+05:30</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>180.150000</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>True</td>\n",
       "      <td>RECEPTIONIST_OR_FRONT_DESK</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>{'IT': 6, 'AF': 3, 'AR': 2, 'OC': 1, 'PU': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>280853182067</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2021-06-28 18:18:00+05:30</td>\n",
       "      <td>2021-07-02 19:19:00+05:30</td>\n",
       "      <td>97.016667</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>70.566667</td>\n",
       "      <td>32.338889</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>{'IT': 4, 'AR': 3, 'OD': 2, 'OC': 1, 'PU': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>280902855329</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>2021-06-29 19:07:00+05:30</td>\n",
       "      <td>2021-07-05 15:57:00+05:30</td>\n",
       "      <td>140.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>87.250000</td>\n",
       "      <td>46.944444</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>{'IT': 6, 'DP': 2, 'AR': 2, 'DE': 2, 'OD': 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>280902966660</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.5</td>\n",
       "      <td>KG</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2021-06-29 19:06:00+05:30</td>\n",
       "      <td>2021-07-02 19:59:00+05:30</td>\n",
       "      <td>72.883333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>62.266667</td>\n",
       "      <td>24.294444</td>\n",
       "      <td>True</td>\n",
       "      <td>IN_BOND_OR_CAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>{'IT': 5, 'AR': 2, 'OC': 1, 'PU': 1, 'DP': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>280993568461</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>1.5</td>\n",
       "      <td>KG</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2021-07-03 16:19:00+05:30</td>\n",
       "      <td>2021-07-06 10:30:00+05:30</td>\n",
       "      <td>66.183333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>41.383333</td>\n",
       "      <td>22.061111</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>{'IT': 3, 'AR': 2, 'OD': 2, 'OC': 1, 'PU': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>280998636780</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>3.8</td>\n",
       "      <td>KG</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Surat</td>\n",
       "      <td>2021-07-03 18:10:00+05:30</td>\n",
       "      <td>2021-07-07 17:34:00+05:30</td>\n",
       "      <td>95.400000</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>70.350000</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>{'IT': 7, 'AR': 2, 'OD': 2, 'OC': 1, 'PU': 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tracking_number         service_type carrier_code  package_weight_value  \\\n",
       "0    280267328981  FEDEX_EXPRESS_SAVER         FDXE                  20.0   \n",
       "1    280267329094  FEDEX_EXPRESS_SAVER         FDXE                  20.0   \n",
       "2    280307632740  FEDEX_EXPRESS_SAVER         FDXE                   2.0   \n",
       "3    280307633276  FEDEX_EXPRESS_SAVER         FDXE                   2.0   \n",
       "4    280439181099  FEDEX_EXPRESS_SAVER         FDXE                  32.0   \n",
       "5    280853182067  FEDEX_EXPRESS_SAVER         FDXE                   5.0   \n",
       "6    280902855329  FEDEX_EXPRESS_SAVER         FDXE                   2.0   \n",
       "7    280902966660  FEDEX_EXPRESS_SAVER         FDXE                   2.5   \n",
       "8    280993568461  FEDEX_EXPRESS_SAVER         FDXE                   1.5   \n",
       "9    280998636780  FEDEX_EXPRESS_SAVER         FDXE                   3.8   \n",
       "\n",
       "  package_weight_units origin_city destination_city       pickup_datetime_ist  \\\n",
       "0                   KG       Delhi        Hyderabad 2021-06-11 18:56:00+05:30   \n",
       "1                   KG       Delhi            Noida 2021-06-11 18:56:00+05:30   \n",
       "2                   KG      Mumbai             Pune 2021-06-14 19:31:00+05:30   \n",
       "3                   KG      Mumbai             Pune 2021-06-14 19:31:00+05:30   \n",
       "4                   KG       Delhi          Chennai 2021-06-16 19:22:00+05:30   \n",
       "5                   KG   Bangalore          Chennai 2021-06-28 18:18:00+05:30   \n",
       "6                   KG   Bangalore            Delhi 2021-06-29 19:07:00+05:30   \n",
       "7                   KG   Bangalore        Hyderabad 2021-06-29 19:06:00+05:30   \n",
       "8                   KG        Pune           Mumbai 2021-07-03 16:19:00+05:30   \n",
       "9                   KG      Mumbai            Surat 2021-07-03 18:10:00+05:30   \n",
       "\n",
       "      delivery_datetime_ist  total_transit_hours  num_facilities_visited  \\\n",
       "0 2021-06-18 17:18:00+05:30           166.366667                       3   \n",
       "1 2021-06-16 11:28:00+05:30           112.533333                       3   \n",
       "2 2021-06-16 16:30:00+05:30            44.983333                       3   \n",
       "3 2021-06-16 16:30:00+05:30            44.983333                       3   \n",
       "4 2021-06-24 18:22:00+05:30           191.000000                       3   \n",
       "5 2021-07-02 19:19:00+05:30            97.016667                       3   \n",
       "6 2021-07-05 15:57:00+05:30           140.833333                       3   \n",
       "7 2021-07-02 19:59:00+05:30            72.883333                       3   \n",
       "8 2021-07-06 10:30:00+05:30            66.183333                       3   \n",
       "9 2021-07-07 17:34:00+05:30            95.400000                       3   \n",
       "\n",
       "   num_in_transit_events  time_in_inter_facility_transit_hours  \\\n",
       "0                     11                            155.633333   \n",
       "1                      9                            107.550000   \n",
       "2                      7                             38.133333   \n",
       "3                      7                             38.166667   \n",
       "4                      9                            180.150000   \n",
       "5                      8                             70.566667   \n",
       "6                     11                             87.250000   \n",
       "7                      7                             62.266667   \n",
       "8                      7                             41.383333   \n",
       "9                     11                             70.350000   \n",
       "\n",
       "   avg_hours_per_facility  is_express_service      delivery_location_type  \\\n",
       "0               55.455556                True             IN_BOND_OR_CAGE   \n",
       "1               37.511111                True  RECEPTIONIST_OR_FRONT_DESK   \n",
       "2               14.994444                True                   RESIDENCE   \n",
       "3               14.994444                True                   RESIDENCE   \n",
       "4               63.666667                True  RECEPTIONIST_OR_FRONT_DESK   \n",
       "5               32.338889                True                   RESIDENCE   \n",
       "6               46.944444                True                   RESIDENCE   \n",
       "7               24.294444                True             IN_BOND_OR_CAGE   \n",
       "8               22.061111                True                   RESIDENCE   \n",
       "9               31.800000                True                   RESIDENCE   \n",
       "\n",
       "   num_out_for_delivery_attempts  first_attempt_delivery  total_events_count  \\\n",
       "0                              0                    True                  16   \n",
       "1                              0                    True                  18   \n",
       "2                              1                    True                  11   \n",
       "3                              1                    True                  11   \n",
       "4                              1                    True                  17   \n",
       "5                              2                   False                  14   \n",
       "6                              2                   False                  17   \n",
       "7                              0                    True                  12   \n",
       "8                              2                   False                  12   \n",
       "9                              2                   False                  16   \n",
       "\n",
       "                                   event_type_counts  \n",
       "0  {'IT': 9, 'AR': 2, 'OC': 1, 'PU': 1, 'DP': 1, ...  \n",
       "1  {'IT': 7, 'AR': 4, 'DE': 2, 'OC': 1, 'PU': 1, ...  \n",
       "2  {'IT': 4, 'OC': 1, 'PU': 1, 'DP': 1, 'AF': 1, ...  \n",
       "3  {'IT': 4, 'OC': 1, 'PU': 1, 'DP': 1, 'AF': 1, ...  \n",
       "4  {'IT': 6, 'AF': 3, 'AR': 2, 'OC': 1, 'PU': 1, ...  \n",
       "5  {'IT': 4, 'AR': 3, 'OD': 2, 'OC': 1, 'PU': 1, ...  \n",
       "6  {'IT': 6, 'DP': 2, 'AR': 2, 'DE': 2, 'OD': 2, ...  \n",
       "7  {'IT': 5, 'AR': 2, 'OC': 1, 'PU': 1, 'DP': 1, ...  \n",
       "8  {'IT': 3, 'AR': 2, 'OD': 2, 'OC': 1, 'PU': 1, ...  \n",
       "9  {'IT': 7, 'AR': 2, 'OD': 2, 'OC': 1, 'PU': 1, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique event types found (global): ['AF', 'AR', 'AS', 'DE', 'DL', 'DP', 'IT', 'OC', 'OD', 'PU', 'SE']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "def parse_timestamp(ts):\n",
    "    \"\"\"\n",
    "    Parse different timestamp formats:\n",
    "     - dict with \"$numberLong\" (milliseconds since epoch)\n",
    "     - ISO string or pandas-parsable string\n",
    "     - datetime objects pass-through\n",
    "    Returns a pandas.Timestamp or NaT.\n",
    "    \"\"\"\n",
    "    if ts is None:\n",
    "        return pd.NaT\n",
    "    # already pandas Timestamp or datetime\n",
    "    if isinstance(ts, (pd.Timestamp, datetime)):\n",
    "        return pd.to_datetime(ts)\n",
    "    # dict with $numberLong\n",
    "    if isinstance(ts, dict) and \"$numberLong\" in ts:\n",
    "        try:\n",
    "            ms = int(ts[\"$numberLong\"])\n",
    "            return pd.to_datetime(ms, unit='ms', utc=True).tz_convert('Asia/Kolkata')\n",
    "        except Exception:\n",
    "            return pd.NaT\n",
    "    # plain numeric string/number (epoch ms or s) - try safe conversions\n",
    "    if isinstance(ts, (int, float)) or (isinstance(ts, str) and ts.isdigit()):\n",
    "        try:\n",
    "            val = int(ts)\n",
    "            if val > 1e12: \n",
    "                return pd.to_datetime(val, unit='ms', utc=True).tz_convert('Asia/Kolkata')\n",
    "            else:\n",
    "                return pd.to_datetime(val, unit='s', utc=True).tz_convert('Asia/Kolkata')\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "    # fallback to pandas parsing (assume timezone info included where present)\n",
    "    try:\n",
    "        parsed = pd.to_datetime(ts, errors='coerce')\n",
    "        if pd.isna(parsed):\n",
    "            return pd.NaT\n",
    "        # if timezone-naive, localize to Asia/Kolkata (IST) for consistent calculations\n",
    "        if parsed.tzinfo is None:\n",
    "            # treat as already in IST if string had +05:30 or else assume IST\n",
    "            try:\n",
    "                return parsed.tz_localize('Asia/Kolkata')\n",
    "            except Exception:\n",
    "                return parsed.tz_convert('Asia/Kolkata') if parsed.tzinfo else parsed\n",
    "        else:\n",
    "            # convert to IST\n",
    "            return parsed.tz_convert('Asia/Kolkata')\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def safe_lower(x):\n",
    "    return x.lower() if isinstance(x, str) else \"\"\n",
    "\n",
    "def contains_any(text, keywords):\n",
    "    txt = safe_lower(text)\n",
    "    return any(k in txt for k in keywords)\n",
    "\n",
    "# Event classification keyword lists (heuristic)\n",
    "IN_TRANSIT_KEYWORDS = [\"in transit\", \"on vehicle\", \"on fedex vehicle\", \"departed\", \"left facility\", \"transit\", \"on truck\", \"in route\"]\n",
    "ARRIVAL_KEYWORDS = [\"arrived\", \"arrival\", \"arrive at\", \"arrived at\", \"at facility\", \"arrival scan\"]\n",
    "OUT_FOR_DELIVERY_KEYWORDS = [\"out for delivery\", \"on vehicle for delivery\", \"on fedex vehicle for delivery\", \"out for delivery -\", \"on truck for delivery\"]\n",
    "\n",
    "# Decide event-type driven buckets (we will also use textual fallback)\n",
    "# These sets can be extended if you discover more codes in your dataset\n",
    "\n",
    "PICKUP_EVENT_TYPES = set([\"PU\", \"PUP\", \"PICKUP\"])   # common pickup codes\n",
    "DELIVERY_EVENT_TYPES = set([\"DL\", \"DE\", \"DEL\"])     # delivery / delivered\n",
    "OUT_FOR_DELIVERY_TYPES = set([\"OD\", \"OF\"])          # often OD (on delivery / out for delivery)\n",
    "FACILITY_SUBSTRING = \"FACILITY\"\n",
    "\n",
    "# -------------------------\n",
    "# Precompute: per-shipment grouping\n",
    "# -------------------------\n",
    "# get list of unique tracking numbers present in df_transit or raw \n",
    "\n",
    "if 'df_transit' not in globals():\n",
    "    # build df_transit quickly as fallback (in case user didn't run Part 2)\n",
    "    # minimal reconstruction: iterate raw data similar to Part 2\n",
    "    flattened_records = []\n",
    "    def get_val(d, path, default=None):\n",
    "        cur = d\n",
    "        for k in path:\n",
    "            if isinstance(cur, dict) and k in cur:\n",
    "                cur = cur[k]\n",
    "            else:\n",
    "                return default\n",
    "        return cur\n",
    "    for rec in data:\n",
    "        for shipment in rec.get(\"trackDetails\", []):\n",
    "            events = shipment.get(\"events\", []) or []\n",
    "            # if no events, still create one row\n",
    "            if not events:\n",
    "                flattened_records.append({\n",
    "                    \"tracking_number\": shipment.get(\"trackingNumber\"),\n",
    "                    \"service_type\": get_val(shipment, [\"service\", \"type\"]),\n",
    "                    \"service_description\": get_val(shipment, [\"service\", \"description\"]),\n",
    "                    \"carrier_code\": shipment.get(\"carrierCode\"),\n",
    "                    \"package_weight_value\": get_val(shipment, [\"packageWeight\", \"value\"]),\n",
    "                    \"package_weight_units\": get_val(shipment, [\"packageWeight\", \"units\"]),\n",
    "                    \"packaging_type\": get_val(shipment, [\"packaging\", \"type\"]),\n",
    "                    \"origin_city\": get_val(shipment, [\"shipperAddress\",\"city\"]),\n",
    "                    \"origin_state\": get_val(shipment, [\"shipperAddress\",\"stateOrProvinceCode\"]),\n",
    "                    \"origin_pincode\": get_val(shipment, [\"shipperAddress\",\"postalCode\"]),\n",
    "                    \"destination_city\": get_val(shipment, [\"destinationAddress\",\"city\"]),\n",
    "                    \"destination_state\": get_val(shipment, [\"destinationAddress\",\"stateOrProvinceCode\"]),\n",
    "                    \"destination_pincode\": get_val(shipment, [\"destinationAddress\",\"postalCode\"]),\n",
    "                    \"event_type\": None,\n",
    "                    \"event_timestamp\": pd.NaT,\n",
    "                    \"event_description\": None,\n",
    "                    \"event_location_city\": None,\n",
    "                    \"event_location_state\": None,\n",
    "                    \"event_location_postal_code\": None,\n",
    "                    \"arrival_location_type\": None,\n",
    "                    \"raw_shipment_obj\": shipment\n",
    "                })\n",
    "            else:\n",
    "                for ev in events:\n",
    "                    flattened_records.append({\n",
    "                        \"tracking_number\": shipment.get(\"trackingNumber\"),\n",
    "                        \"service_type\": get_val(shipment, [\"service\", \"type\"]),\n",
    "                        \"service_description\": get_val(shipment, [\"service\", \"description\"]),\n",
    "                        \"carrier_code\": shipment.get(\"carrierCode\"),\n",
    "                        \"package_weight_value\": get_val(shipment, [\"packageWeight\", \"value\"]),\n",
    "                        \"package_weight_units\": get_val(shipment, [\"packageWeight\", \"units\"]),\n",
    "                        \"packaging_type\": get_val(shipment, [\"packaging\", \"type\"]),\n",
    "                        \"origin_city\": get_val(shipment, [\"shipperAddress\",\"city\"]),\n",
    "                        \"origin_state\": get_val(shipment, [\"shipperAddress\",\"stateOrProvinceCode\"]),\n",
    "                        \"origin_pincode\": get_val(shipment, [\"shipperAddress\",\"postalCode\"]),\n",
    "                        \"destination_city\": get_val(shipment, [\"destinationAddress\",\"city\"]),\n",
    "                        \"destination_state\": get_val(shipment, [\"destinationAddress\",\"stateOrProvinceCode\"]),\n",
    "                        \"destination_pincode\": get_val(shipment, [\"destinationAddress\",\"postalCode\"]),\n",
    "                        \"event_type\": ev.get(\"eventType\"),\n",
    "                        \"event_timestamp\": ev.get(\"timestamp\"),\n",
    "                        \"event_description\": ev.get(\"eventDescription\"),\n",
    "                        \"event_location_city\": (ev.get(\"address\") or {}).get(\"city\"),\n",
    "                        \"event_location_state\": (ev.get(\"address\") or {}).get(\"stateOrProvinceCode\"),\n",
    "                        \"event_location_postal_code\": (ev.get(\"address\") or {}).get(\"postalCode\"),\n",
    "                        \"arrival_location_type\": ev.get(\"arrivalLocation\"),\n",
    "                        \"raw_shipment_obj\": shipment\n",
    "                    })\n",
    "    df_transit = pd.DataFrame(flattened_records)\n",
    "\n",
    "# Ensure event_timestamp parsed consistently\n",
    "\n",
    "if 'event_timestamp' in df_transit.columns:\n",
    "    df_transit['event_timestamp_parsed'] = df_transit['event_timestamp'].apply(parse_timestamp)\n",
    "\n",
    "# Build mapping from tracking_number -> original shipment object (for datesOrTimes and deliveryLocationType)\n",
    "\n",
    "shipment_lookup = {}\n",
    "for rec in data:\n",
    "    for shp in rec.get(\"trackDetails\", []):\n",
    "        tn = shp.get(\"trackingNumber\")\n",
    "        if tn:\n",
    "            shipment_lookup[tn] = shp\n",
    "\n",
    "unique_event_types = sorted(df_transit['event_type'].dropna().unique().tolist())\n",
    "print(\"Unique event types in dataset:\", unique_event_types)\n",
    "\n",
    "metrics = []\n",
    "grouped = df_transit.groupby('tracking_number', dropna=False)\n",
    "\n",
    "for tracking_number, group in grouped:\n",
    "    service_type = group['service_type'].dropna().iloc[0] if group['service_type'].dropna().any() else None\n",
    "    carrier_code = group['carrier_code'].dropna().iloc[0] if group['carrier_code'].dropna().any() else None\n",
    "    delivery_location_type = None\n",
    "    shp_obj = shipment_lookup.get(tracking_number)\n",
    "    if shp_obj:\n",
    "        delivery_location_type = shp_obj.get('deliveryLocationType')\n",
    "    \n",
    "    group = group.copy()\n",
    "    if 'event_timestamp_parsed' not in group.columns:\n",
    "        group['event_timestamp_parsed'] = group['event_timestamp'].apply(parse_timestamp)\n",
    "    group = group.sort_values(by='event_timestamp_parsed', na_position='last').reset_index(drop=True)\n",
    "    \n",
    "    # Unique facility touchpoints: distinct arrivalLocation values containing \"FACILITY\"\n",
    "    # also consider event-level arrival_location_type column if present\n",
    "    \n",
    "    facility_events = group[\n",
    "        group['arrival_location_type'].astype(str).str.contains(FACILITY_SUBSTRING, case=False, na=False)\n",
    "    ].copy()\n",
    "    unique_facilities = facility_events['arrival_location_type'].dropna().unique().tolist()\n",
    "    num_unique_facilities = len(unique_facilities)\n",
    "\n",
    "    event_type_counts = group['event_type'].fillna('UNKNOWN').value_counts().to_dict()\n",
    "\n",
    "    def is_in_transit_row(row):\n",
    "        et = safe_lower(row.get('event_type') or \"\")\n",
    "        desc = row.get('event_description') or \"\"\n",
    "        # check explicit type codes\n",
    "        if row.get('event_type') in IN_TRANSIT_KEYWORDS:  # rare - leave for completeness\n",
    "            return True\n",
    "        # if eventType is one of typical in-transit codes\n",
    "        if row.get('event_type') in (\"IT\", \"TR\", \"DP\", \"OC\", \"OD\"):  # 'OD' sometimes means out for delivery though\n",
    "            return True\n",
    "        # textual check\n",
    "        if contains_any(desc, IN_TRANSIT_KEYWORDS):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    num_in_transit_events = group.apply(is_in_transit_row, axis=1).sum()\n",
    "    \n",
    "    # Identify pickup and delivery times (best-effort)\n",
    "    pickup_ts = pd.NaT\n",
    "    delivery_ts = pd.NaT\n",
    "    \n",
    "    # 1) Prefer datesOrTimes entries on shipment (ACTUAL_PICKUP, ACTUAL_TENDER for pickup; ACTUAL_DELIVERY for delivery)\n",
    "    if shp_obj:\n",
    "        for dt in shp_obj.get('datesOrTimes', []) or []:\n",
    "            try:\n",
    "                dtype = dt.get('type', '').upper()\n",
    "                raw = dt.get('dateOrTimestamp')\n",
    "                parsed = parse_timestamp(raw)\n",
    "                if dtype == 'ACTUAL_PICKUP' or dtype == 'ACTUAL_TENDER':\n",
    "                    # choose earliest of these if multiple\n",
    "                    if pd.isna(pickup_ts) or parsed < pickup_ts:\n",
    "                        pickup_ts = parsed\n",
    "                elif dtype == 'ACTUAL_DELIVERY':\n",
    "                    if pd.isna(delivery_ts) or parsed > delivery_ts:\n",
    "                        delivery_ts = parsed\n",
    "            except Exception:\n",
    "                continue\n",
    "    \n",
    "    # 2) Fallback to events: pickup = first event that looks like a pickup; delivery = last that looks like delivery\n",
    "    # Find pickup in events\n",
    "    if pd.isna(pickup_ts):\n",
    "        # scan events in chronological order\n",
    "        for _, row in group.iterrows():\n",
    "            desc = row.get('event_description') or \"\"\n",
    "            etype = (row.get('event_type') or \"\").upper()\n",
    "            ts = row.get('event_timestamp_parsed')\n",
    "            # check eventType tokens and description\n",
    "            if etype in PICKUP_EVENT_TYPES or contains_any(desc, [\"pickup\", \"picked up\", \"tendered\"]):\n",
    "                pickup_ts = ts\n",
    "                break\n",
    "        if pd.isna(pickup_ts) and group['event_timestamp_parsed'].notna().any():\n",
    "            pickup_ts = group['event_timestamp_parsed'].min()\n",
    "    \n",
    "    if pd.isna(delivery_ts):\n",
    "        # reverse chronological scan to find \"delivered\" or DL\n",
    "        for _, row in group.iloc[::-1].iterrows():\n",
    "            desc = row.get('event_description') or \"\"\n",
    "            etype = (row.get('event_type') or \"\").upper()\n",
    "            ts = row.get('event_timestamp_parsed')\n",
    "            if etype in DELIVERY_EVENT_TYPES or contains_any(desc, [\"delivered\", \"delivery\"]):\n",
    "                delivery_ts = ts\n",
    "                break\n",
    "        # fallback: latest event timestamp\n",
    "        if pd.isna(delivery_ts) and group['event_timestamp_parsed'].notna().any():\n",
    "            delivery_ts = group['event_timestamp_parsed'].max()\n",
    "    \n",
    "    # Compute total transit hours (pickup -> delivery)\n",
    "    total_transit_hours = np.nan\n",
    "    if pd.notna(pickup_ts) and pd.notna(delivery_ts):\n",
    "        # ensure both in same tz and compute hours\n",
    "        try:\n",
    "            delta = delivery_ts - pickup_ts\n",
    "            total_transit_hours = delta.total_seconds() / 3600.0\n",
    "            # if negative (bad data), set to NaN\n",
    "            if total_transit_hours < 0:\n",
    "                total_transit_hours = np.nan\n",
    "        except Exception:\n",
    "            total_transit_hours = np.nan\n",
    "    \n",
    "    # Inter-facility transit time:\n",
    "    # We'll compute time between successive facility event timestamps (i.e., travel time between facilities)\n",
    "    # Sum of (timestamp_next_facility - timestamp_prev_facility)\n",
    "    time_in_inter_facility_hours = np.nan\n",
    "    if len(facility_events) >= 2:\n",
    "        # ensure parsed timestamps for facility_events\n",
    "        fac_ts = facility_events['event_timestamp_parsed'].dropna().sort_values()\n",
    "        if len(fac_ts) >= 2:\n",
    "            diffs = fac_ts.diff().dropna().dt.total_seconds() / 3600.0\n",
    "            # sum positive diffs (ignore negative/nonsensical)\n",
    "            positive_sum = diffs[diffs > 0].sum()\n",
    "            time_in_inter_facility_hours = float(positive_sum)\n",
    "        else:\n",
    "            time_in_inter_facility_hours = 0.0\n",
    "    elif len(facility_events) == 1:\n",
    "        # only one facility touchpoint — inter-facility transit undefined; set 0.0\n",
    "        time_in_inter_facility_hours = 0.0\n",
    "    else:\n",
    "        # no facility events found\n",
    "        time_in_inter_facility_hours = 0.0\n",
    "    \n",
    "    # Transit velocity: avg hours per facility\n",
    "    avg_hours_per_facility = np.nan\n",
    "    if num_unique_facilities > 0 and pd.notna(total_transit_hours):\n",
    "        avg_hours_per_facility = total_transit_hours / num_unique_facilities\n",
    "    elif num_unique_facilities > 0 and pd.isna(total_transit_hours):\n",
    "        avg_hours_per_facility = np.nan\n",
    "    else:\n",
    "        avg_hours_per_facility = np.nan\n",
    "    \n",
    "    # Service category classification (simple heuristics)\n",
    "    svc = service_type or \"\"\n",
    "    svc_upper = svc.upper() if isinstance(svc, str) else \"\"\n",
    "    if \"EXPRESS\" in svc_upper or \"XS\" in svc_upper or \"FEDEX_EXPRESS\" in svc_upper or \"PRIORITY\" in svc_upper:\n",
    "        is_express_service = True\n",
    "    elif \"ECONOMY\" in svc_upper or \"STANDARD\" in svc_upper or \"GROUND\" in svc_upper:\n",
    "        is_express_service = False\n",
    "    else:\n",
    "        # Unknown -> treat as False but keep as 'unknown' if needed\n",
    "        is_express_service = False\n",
    "    \n",
    "    # Delivery Characteristics: out-for-delivery attempts\n",
    "    def is_out_for_delivery_row(row):\n",
    "        et = (row.get('event_type') or \"\").upper()\n",
    "        desc = row.get('event_description') or \"\"\n",
    "        if et in OUT_FOR_DELIVERY_TYPES or 'OD' == et or contains_any(desc, OUT_FOR_DELIVERY_KEYWORDS):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    num_out_for_delivery_attempts = group.apply(is_out_for_delivery_row, axis=1).sum()\n",
    "    first_attempt_delivery = None\n",
    "    \n",
    "    # if delivered and number of out-for-delivery attempts == 1 then True; if 0 and delivered maybe direct delivered; treat as True\n",
    "    # We'll inspect whether a delivery event exists\n",
    "    \n",
    "    delivered_exists = group.apply(lambda r: ((r.get('event_type') or \"\").upper() in DELIVERY_EVENT_TYPES) or contains_any(r.get('event_description') or \"\", [\"delivered\"]), axis=1).any()\n",
    "    if delivered_exists:\n",
    "        # Consider TRUE if <=1 OFD events\n",
    "        first_attempt_delivery = (num_out_for_delivery_attempts <= 1)\n",
    "    else:\n",
    "        first_attempt_delivery = False  # not delivered yet\n",
    "    \n",
    "    # total events count\n",
    "    total_events_count = len(group)\n",
    "    \n",
    "    # assemble metrics\n",
    "    metrics.append({\n",
    "        \"tracking_number\": tracking_number,\n",
    "        \"service_type\": service_type,\n",
    "        \"carrier_code\": carrier_code,\n",
    "        \"package_weight_value\": group['package_weight_value'].dropna().iloc[0] if group['package_weight_value'].dropna().any() else None,\n",
    "        \"package_weight_units\": group['package_weight_units'].dropna().iloc[0] if group['package_weight_units'].dropna().any() else None,\n",
    "        \"origin_city\": group['origin_city'].dropna().iloc[0] if group['origin_city'].dropna().any() else None,\n",
    "        \"destination_city\": group['destination_city'].dropna().iloc[0] if group['destination_city'].dropna().any() else None,\n",
    "        \"pickup_datetime_ist\": pickup_ts,\n",
    "        \"delivery_datetime_ist\": delivery_ts,\n",
    "        \"total_transit_hours\": total_transit_hours,\n",
    "        \"num_facilities_visited\": num_unique_facilities,\n",
    "        \"num_in_transit_events\": int(num_in_transit_events),\n",
    "        \"time_in_inter_facility_transit_hours\": time_in_inter_facility_hours,\n",
    "        \"avg_hours_per_facility\": avg_hours_per_facility,\n",
    "        \"is_express_service\": bool(is_express_service),\n",
    "        \"delivery_location_type\": delivery_location_type,\n",
    "        \"num_out_for_delivery_attempts\": int(num_out_for_delivery_attempts),\n",
    "        \"first_attempt_delivery\": bool(first_attempt_delivery),\n",
    "        \"total_events_count\": int(total_events_count),\n",
    "        \"event_type_counts\": event_type_counts\n",
    "    })\n",
    "\n",
    "# Final metrics DataFrame\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "\n",
    "# Ensure timestamp columns are pandas datetime and in IST tz\n",
    "if 'pickup_datetime_ist' in df_metrics.columns:\n",
    "    df_metrics['pickup_datetime_ist'] = pd.to_datetime(df_metrics['pickup_datetime_ist'])\n",
    "    # convert to tz 'Asia/Kolkata' if naive\n",
    "    df_metrics['pickup_datetime_ist'] = df_metrics['pickup_datetime_ist'].apply(lambda x: x.tz_convert('Asia/Kolkata') if hasattr(x, 'tzinfo') and x.tzinfo else (x.tz_localize('Asia/Kolkata') if pd.notna(x) else x))\n",
    "if 'delivery_datetime_ist' in df_metrics.columns:\n",
    "    df_metrics['delivery_datetime_ist'] = pd.to_datetime(df_metrics['delivery_datetime_ist'])\n",
    "    df_metrics['delivery_datetime_ist'] = df_metrics['delivery_datetime_ist'].apply(lambda x: x.tz_convert('Asia/Kolkata') if hasattr(x, 'tzinfo') and x.tzinfo else (x.tz_localize('Asia/Kolkata') if pd.notna(x) else x))\n",
    "\n",
    "# Quick sanity checks / display\n",
    "print(\"Computation complete. Per-shipment metrics generated for\", len(df_metrics), \"shipments.\\n\")\n",
    "display(df_metrics.head(10))\n",
    "\n",
    "# Also expose the global unique_event_types which may be useful downstream\n",
    "print(\"\\nUnique event types found (global):\", unique_event_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e79150",
   "metadata": {},
   "source": [
    "## Part 4: Handle Edge Cases\n",
    "### Objective:\n",
    "Clean and validate the data produced so far (df_transit and df_metrics)\n",
    "to ensure robustness against:\n",
    "- Missing/null fields\n",
    "- Timestamps in mixed formats\n",
    "- Incomplete event sequences\n",
    "- Missing address information\n",
    "- Duplicate events\n",
    "- Empty or missing events arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f227cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning missing or null values...\n",
      "Normalizing timestamp formats...\n",
      "Removing duplicate events (same tracking number + timestamp)...\n",
      "Handling missing or empty events arrays...\n",
      "Checking for incomplete event sequences...\n",
      "Replacing missing address fields...\n",
      "Edge case handling complete!\n",
      "\n",
      "Total shipments (unique): 99\n",
      "Total events (after cleaning): 1196\n",
      "Incomplete shipments flagged: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracking_number</th>\n",
       "      <th>service_type</th>\n",
       "      <th>carrier_code</th>\n",
       "      <th>package_weight_value</th>\n",
       "      <th>package_weight_units</th>\n",
       "      <th>origin_city</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>pickup_datetime_ist</th>\n",
       "      <th>delivery_datetime_ist</th>\n",
       "      <th>total_transit_hours</th>\n",
       "      <th>...</th>\n",
       "      <th>num_in_transit_events</th>\n",
       "      <th>time_in_inter_facility_transit_hours</th>\n",
       "      <th>avg_hours_per_facility</th>\n",
       "      <th>is_express_service</th>\n",
       "      <th>delivery_location_type</th>\n",
       "      <th>num_out_for_delivery_attempts</th>\n",
       "      <th>first_attempt_delivery</th>\n",
       "      <th>total_events_count</th>\n",
       "      <th>event_type_counts</th>\n",
       "      <th>is_incomplete_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280267328981</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2021-06-11 18:56:00+05:30</td>\n",
       "      <td>2021-06-18 17:18:00+05:30</td>\n",
       "      <td>166.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>155.633333</td>\n",
       "      <td>55.455556</td>\n",
       "      <td>True</td>\n",
       "      <td>IN_BOND_OR_CAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>{'IT': 9, 'AR': 2, 'OC': 1, 'PU': 1, 'DP': 1, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280267329094</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Noida</td>\n",
       "      <td>2021-06-11 18:56:00+05:30</td>\n",
       "      <td>2021-06-16 11:28:00+05:30</td>\n",
       "      <td>112.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>107.550000</td>\n",
       "      <td>37.511111</td>\n",
       "      <td>True</td>\n",
       "      <td>RECEPTIONIST_OR_FRONT_DESK</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>{'IT': 7, 'AR': 4, 'DE': 2, 'OC': 1, 'PU': 1, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280307632740</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2021-06-14 19:31:00+05:30</td>\n",
       "      <td>2021-06-16 16:30:00+05:30</td>\n",
       "      <td>44.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>38.133333</td>\n",
       "      <td>14.994444</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>{'IT': 4, 'OC': 1, 'PU': 1, 'DP': 1, 'AF': 1, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280307633276</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2021-06-14 19:31:00+05:30</td>\n",
       "      <td>2021-06-16 16:30:00+05:30</td>\n",
       "      <td>44.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>38.166667</td>\n",
       "      <td>14.994444</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>{'IT': 4, 'OC': 1, 'PU': 1, 'DP': 1, 'AF': 1, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>280439181099</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>32.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2021-06-16 19:22:00+05:30</td>\n",
       "      <td>2021-06-24 18:22:00+05:30</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>180.150000</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>True</td>\n",
       "      <td>RECEPTIONIST_OR_FRONT_DESK</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>{'IT': 6, 'AF': 3, 'AR': 2, 'OC': 1, 'PU': 1, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tracking_number         service_type carrier_code  package_weight_value  \\\n",
       "0    280267328981  FEDEX_EXPRESS_SAVER         FDXE                  20.0   \n",
       "1    280267329094  FEDEX_EXPRESS_SAVER         FDXE                  20.0   \n",
       "2    280307632740  FEDEX_EXPRESS_SAVER         FDXE                   2.0   \n",
       "3    280307633276  FEDEX_EXPRESS_SAVER         FDXE                   2.0   \n",
       "4    280439181099  FEDEX_EXPRESS_SAVER         FDXE                  32.0   \n",
       "\n",
       "  package_weight_units origin_city destination_city       pickup_datetime_ist  \\\n",
       "0                   KG       Delhi        Hyderabad 2021-06-11 18:56:00+05:30   \n",
       "1                   KG       Delhi            Noida 2021-06-11 18:56:00+05:30   \n",
       "2                   KG      Mumbai             Pune 2021-06-14 19:31:00+05:30   \n",
       "3                   KG      Mumbai             Pune 2021-06-14 19:31:00+05:30   \n",
       "4                   KG       Delhi          Chennai 2021-06-16 19:22:00+05:30   \n",
       "\n",
       "      delivery_datetime_ist  total_transit_hours  ...  num_in_transit_events  \\\n",
       "0 2021-06-18 17:18:00+05:30           166.366667  ...                     11   \n",
       "1 2021-06-16 11:28:00+05:30           112.533333  ...                      9   \n",
       "2 2021-06-16 16:30:00+05:30            44.983333  ...                      7   \n",
       "3 2021-06-16 16:30:00+05:30            44.983333  ...                      7   \n",
       "4 2021-06-24 18:22:00+05:30           191.000000  ...                      9   \n",
       "\n",
       "   time_in_inter_facility_transit_hours  avg_hours_per_facility  \\\n",
       "0                            155.633333               55.455556   \n",
       "1                            107.550000               37.511111   \n",
       "2                             38.133333               14.994444   \n",
       "3                             38.166667               14.994444   \n",
       "4                            180.150000               63.666667   \n",
       "\n",
       "   is_express_service      delivery_location_type  \\\n",
       "0                True             IN_BOND_OR_CAGE   \n",
       "1                True  RECEPTIONIST_OR_FRONT_DESK   \n",
       "2                True                   RESIDENCE   \n",
       "3                True                   RESIDENCE   \n",
       "4                True  RECEPTIONIST_OR_FRONT_DESK   \n",
       "\n",
       "  num_out_for_delivery_attempts  first_attempt_delivery  total_events_count  \\\n",
       "0                             0                    True                  16   \n",
       "1                             0                    True                  18   \n",
       "2                             1                    True                  11   \n",
       "3                             1                    True                  11   \n",
       "4                             1                    True                  17   \n",
       "\n",
       "                                   event_type_counts is_incomplete_sequence  \n",
       "0  {'IT': 9, 'AR': 2, 'OC': 1, 'PU': 1, 'DP': 1, ...                  False  \n",
       "1  {'IT': 7, 'AR': 4, 'DE': 2, 'OC': 1, 'PU': 1, ...                  False  \n",
       "2  {'IT': 4, 'OC': 1, 'PU': 1, 'DP': 1, 'AF': 1, ...                  False  \n",
       "3  {'IT': 4, 'OC': 1, 'PU': 1, 'DP': 1, 'AF': 1, ...                  False  \n",
       "4  {'IT': 6, 'AF': 3, 'AR': 2, 'OC': 1, 'PU': 1, ...                  False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safe_parse_timestamp(ts):\n",
    "    \"\"\"Wrapper to re-parse timestamps robustly; fallbacks included.\"\"\"\n",
    "    try:\n",
    "        if isinstance(ts, pd.Timestamp):\n",
    "            return ts\n",
    "        if isinstance(ts, dict) and \"$numberLong\" in ts:\n",
    "            return pd.to_datetime(int(ts[\"$numberLong\"]), unit=\"ms\", errors=\"coerce\")\n",
    "        return pd.to_datetime(ts, errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def fill_missing_str(series, fill=\"UNKNOWN\"):\n",
    "    \"\"\"Replace missing string values with a safe placeholder.\"\"\"\n",
    "    return series.fillna(fill).replace(\"\", fill)\n",
    "\n",
    "print(\"Cleaning missing or null values...\")\n",
    "\n",
    "string_cols = [\n",
    "    \"tracking_number\",\"service_type\",\"service_description\",\"carrier_code\",\n",
    "    \"packaging_type\",\"origin_city\",\"origin_state\",\"origin_pincode\",\n",
    "    \"destination_city\",\"destination_state\",\"destination_pincode\",\n",
    "    \"event_type\",\"event_description\",\"event_location_city\",\n",
    "    \"event_location_state\",\"event_location_postal_code\",\"arrival_location_type\"\n",
    "]\n",
    "for col in string_cols:\n",
    "    if col in df_transit.columns:\n",
    "        df_transit[col] = fill_missing_str(df_transit[col])\n",
    "\n",
    "# Replace NaN numeric fields with 0 or a sentinel\n",
    "for col in [\"package_weight_value\"]:\n",
    "    if col in df_transit.columns:\n",
    "        df_transit[col] = pd.to_numeric(df_transit[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "print(\"Normalizing timestamp formats...\")\n",
    "\n",
    "if \"event_timestamp\" in df_transit.columns:\n",
    "    df_transit[\"event_timestamp_parsed\"] = df_transit[\"event_timestamp\"].apply(safe_parse_timestamp)\n",
    "    df_transit[\"event_timestamp_parsed\"] = (\n",
    "        df_transit[\"event_timestamp_parsed\"]\n",
    "        .apply(lambda x: x.tz_localize(\"Asia/Kolkata\") if pd.notna(x) and x.tzinfo is None else x)\n",
    "        .apply(lambda x: x.tz_convert(\"Asia/Kolkata\") if pd.notna(x) else x)\n",
    "    )\n",
    "\n",
    "print(\"Removing duplicate events (same tracking number + timestamp)...\")\n",
    "\n",
    "df_transit = df_transit.sort_values([\"tracking_number\",\"event_timestamp_parsed\"])\n",
    "df_transit = df_transit.drop_duplicates(subset=[\"tracking_number\",\"event_timestamp_parsed\"], keep=\"first\")\n",
    "\n",
    "print(\"Handling missing or empty events arrays...\")\n",
    "\n",
    "# For shipments with no events, we already created placeholder rows in Part 2.\n",
    "# Reconfirm at least one row per tracking number.\n",
    "all_tracking_numbers = set([shp.get(\"trackingNumber\") for rec in data for shp in rec.get(\"trackDetails\", [])])\n",
    "missing_shipments = all_tracking_numbers - set(df_transit[\"tracking_number\"].unique())\n",
    "\n",
    "if missing_shipments:\n",
    "    placeholder_rows = []\n",
    "    for tn in missing_shipments:\n",
    "        shp_obj = shipment_lookup.get(tn, {})\n",
    "        placeholder_rows.append({\n",
    "            \"tracking_number\": tn,\n",
    "            \"service_type\": (shp_obj.get(\"service\") or {}).get(\"type\",\"UNKNOWN\"),\n",
    "            \"service_description\": (shp_obj.get(\"service\") or {}).get(\"description\",\"UNKNOWN\"),\n",
    "            \"carrier_code\": shp_obj.get(\"carrierCode\",\"UNKNOWN\"),\n",
    "            \"package_weight_value\": (shp_obj.get(\"packageWeight\") or {}).get(\"value\",0),\n",
    "            \"package_weight_units\": (shp_obj.get(\"packageWeight\") or {}).get(\"units\",\"KG\"),\n",
    "            \"packaging_type\": (shp_obj.get(\"packaging\") or {}).get(\"type\",\"UNKNOWN\"),\n",
    "            \"origin_city\": (shp_obj.get(\"shipperAddress\") or {}).get(\"city\",\"UNKNOWN\"),\n",
    "            \"origin_state\": (shp_obj.get(\"shipperAddress\") or {}).get(\"stateOrProvinceCode\",\"UNKNOWN\"),\n",
    "            \"origin_pincode\": (shp_obj.get(\"shipperAddress\") or {}).get(\"postalCode\",\"UNKNOWN\"),\n",
    "            \"destination_city\": (shp_obj.get(\"destinationAddress\") or {}).get(\"city\",\"UNKNOWN\"),\n",
    "            \"destination_state\": (shp_obj.get(\"destinationAddress\") or {}).get(\"stateOrProvinceCode\",\"UNKNOWN\"),\n",
    "            \"destination_pincode\": (shp_obj.get(\"destinationAddress\") or {}).get(\"postalCode\",\"UNKNOWN\"),\n",
    "            \"event_type\": \"NO_EVENT\",\n",
    "            \"event_timestamp_parsed\": pd.NaT,\n",
    "            \"event_description\": \"No events recorded\",\n",
    "            \"event_location_city\": \"UNKNOWN\",\n",
    "            \"event_location_state\": \"UNKNOWN\",\n",
    "            \"event_location_postal_code\": \"UNKNOWN\",\n",
    "            \"arrival_location_type\": \"NONE\"\n",
    "        })\n",
    "    df_transit = pd.concat([df_transit, pd.DataFrame(placeholder_rows)], ignore_index=True)\n",
    "\n",
    "# ---------- Handle incomplete event sequences ----------\n",
    "print(\"Checking for incomplete event sequences...\")\n",
    "\n",
    "# Mark shipments missing pickup/delivery as incomplete\n",
    "df_metrics[\"is_incomplete_sequence\"] = df_metrics.apply(\n",
    "    lambda x: pd.isna(x[\"pickup_datetime_ist\"]) or pd.isna(x[\"delivery_datetime_ist\"]), axis=1\n",
    ")\n",
    "\n",
    "# Fill missing times with NaT-safe fallback\n",
    "df_metrics[\"pickup_datetime_ist\"] = pd.to_datetime(df_metrics[\"pickup_datetime_ist\"], errors=\"coerce\")\n",
    "df_metrics[\"delivery_datetime_ist\"] = pd.to_datetime(df_metrics[\"delivery_datetime_ist\"], errors=\"coerce\")\n",
    "\n",
    "# If pickup or delivery missing, set total_transit_hours to NaN\n",
    "df_metrics.loc[df_metrics[\"is_incomplete_sequence\"], \"total_transit_hours\"] = np.nan\n",
    "\n",
    "print(\"Replacing missing address fields...\")\n",
    "\n",
    "for col in [\"origin_city\",\"destination_city\",\"origin_state\",\"destination_state\"]:\n",
    "    if col in df_metrics.columns:\n",
    "        df_metrics[col] = fill_missing_str(df_metrics[col])\n",
    "\n",
    "print(\"Edge case handling complete!\")\n",
    "\n",
    "print(f\"\\nTotal shipments (unique): {df_metrics['tracking_number'].nunique()}\")\n",
    "print(f\"Total events (after cleaning): {len(df_transit)}\")\n",
    "print(f\"Incomplete shipments flagged: {df_metrics['is_incomplete_sequence'].sum()}\")\n",
    "\n",
    "display(df_metrics.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b89c6",
   "metadata": {},
   "source": [
    "## Part 5 (Fixed): Output Detailed Transit CSV\n",
    "\n",
    "### Objective:\n",
    "Create transit_performance_detailed.csv with all required columns.\n",
    "Automatically handles missing columns safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b901729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed transit performance CSV created successfully!\n",
      "File Path: C:\\Users\\Alok verma\\transit_performance_detailed.csv\n",
      "Total Shipments Exported: 99\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracking_number</th>\n",
       "      <th>service_type</th>\n",
       "      <th>carrier_code</th>\n",
       "      <th>package_weight_kg</th>\n",
       "      <th>packaging_type</th>\n",
       "      <th>origin_city</th>\n",
       "      <th>origin_state</th>\n",
       "      <th>origin_pincode</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>destination_state</th>\n",
       "      <th>...</th>\n",
       "      <th>total_transit_hours</th>\n",
       "      <th>num_facilities_visited</th>\n",
       "      <th>num_in_transit_events</th>\n",
       "      <th>time_in_inter_facility_transit_hours</th>\n",
       "      <th>avg_hours_per_facility</th>\n",
       "      <th>is_express_service</th>\n",
       "      <th>delivery_location_type</th>\n",
       "      <th>num_out_for_delivery_attempts</th>\n",
       "      <th>first_attempt_delivery</th>\n",
       "      <th>total_events_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280267328981</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>166.366667</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>155.633333</td>\n",
       "      <td>55.455556</td>\n",
       "      <td>True</td>\n",
       "      <td>IN_BOND_OR_CAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280267329094</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Noida</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>112.533333</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>107.550000</td>\n",
       "      <td>37.511111</td>\n",
       "      <td>True</td>\n",
       "      <td>RECEPTIONIST_OR_FRONT_DESK</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280307632740</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Pune</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>44.983333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>38.133333</td>\n",
       "      <td>14.994444</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280307633276</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Pune</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>44.983333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>38.166667</td>\n",
       "      <td>14.994444</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>280439181099</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>32.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>180.150000</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>True</td>\n",
       "      <td>RECEPTIONIST_OR_FRONT_DESK</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>280853182067</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>97.016667</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>70.566667</td>\n",
       "      <td>32.338889</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>280902855329</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>140.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>87.250000</td>\n",
       "      <td>46.944444</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>280902966660</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>2.5</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>72.883333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>62.266667</td>\n",
       "      <td>24.294444</td>\n",
       "      <td>True</td>\n",
       "      <td>IN_BOND_OR_CAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>280993568461</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>1.5</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Pune</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>66.183333</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>41.383333</td>\n",
       "      <td>22.061111</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>280998636780</td>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>FDXE</td>\n",
       "      <td>3.8</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Surat</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>95.400000</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>70.350000</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>True</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tracking_number         service_type carrier_code  package_weight_kg  \\\n",
       "0    280267328981  FEDEX_EXPRESS_SAVER         FDXE               20.0   \n",
       "1    280267329094  FEDEX_EXPRESS_SAVER         FDXE               20.0   \n",
       "2    280307632740  FEDEX_EXPRESS_SAVER         FDXE                2.0   \n",
       "3    280307633276  FEDEX_EXPRESS_SAVER         FDXE                2.0   \n",
       "4    280439181099  FEDEX_EXPRESS_SAVER         FDXE               32.0   \n",
       "5    280853182067  FEDEX_EXPRESS_SAVER         FDXE                5.0   \n",
       "6    280902855329  FEDEX_EXPRESS_SAVER         FDXE                2.0   \n",
       "7    280902966660  FEDEX_EXPRESS_SAVER         FDXE                2.5   \n",
       "8    280993568461  FEDEX_EXPRESS_SAVER         FDXE                1.5   \n",
       "9    280998636780  FEDEX_EXPRESS_SAVER         FDXE                3.8   \n",
       "\n",
       "  packaging_type origin_city origin_state origin_pincode destination_city  \\\n",
       "0        UNKNOWN       Delhi      UNKNOWN        UNKNOWN        Hyderabad   \n",
       "1        UNKNOWN       Delhi      UNKNOWN        UNKNOWN            Noida   \n",
       "2        UNKNOWN      Mumbai      UNKNOWN        UNKNOWN             Pune   \n",
       "3        UNKNOWN      Mumbai      UNKNOWN        UNKNOWN             Pune   \n",
       "4        UNKNOWN       Delhi      UNKNOWN        UNKNOWN          Chennai   \n",
       "5        UNKNOWN   Bangalore      UNKNOWN        UNKNOWN          Chennai   \n",
       "6        UNKNOWN   Bangalore      UNKNOWN        UNKNOWN            Delhi   \n",
       "7        UNKNOWN   Bangalore      UNKNOWN        UNKNOWN        Hyderabad   \n",
       "8        UNKNOWN        Pune      UNKNOWN        UNKNOWN           Mumbai   \n",
       "9        UNKNOWN      Mumbai      UNKNOWN        UNKNOWN            Surat   \n",
       "\n",
       "  destination_state  ... total_transit_hours num_facilities_visited  \\\n",
       "0           UNKNOWN  ...          166.366667                      3   \n",
       "1           UNKNOWN  ...          112.533333                      3   \n",
       "2           UNKNOWN  ...           44.983333                      3   \n",
       "3           UNKNOWN  ...           44.983333                      3   \n",
       "4           UNKNOWN  ...          191.000000                      3   \n",
       "5           UNKNOWN  ...           97.016667                      3   \n",
       "6           UNKNOWN  ...          140.833333                      3   \n",
       "7           UNKNOWN  ...           72.883333                      3   \n",
       "8           UNKNOWN  ...           66.183333                      3   \n",
       "9           UNKNOWN  ...           95.400000                      3   \n",
       "\n",
       "  num_in_transit_events  time_in_inter_facility_transit_hours  \\\n",
       "0                    11                            155.633333   \n",
       "1                     9                            107.550000   \n",
       "2                     7                             38.133333   \n",
       "3                     7                             38.166667   \n",
       "4                     9                            180.150000   \n",
       "5                     8                             70.566667   \n",
       "6                    11                             87.250000   \n",
       "7                     7                             62.266667   \n",
       "8                     7                             41.383333   \n",
       "9                    11                             70.350000   \n",
       "\n",
       "   avg_hours_per_facility  is_express_service      delivery_location_type  \\\n",
       "0               55.455556                True             IN_BOND_OR_CAGE   \n",
       "1               37.511111                True  RECEPTIONIST_OR_FRONT_DESK   \n",
       "2               14.994444                True                   RESIDENCE   \n",
       "3               14.994444                True                   RESIDENCE   \n",
       "4               63.666667                True  RECEPTIONIST_OR_FRONT_DESK   \n",
       "5               32.338889                True                   RESIDENCE   \n",
       "6               46.944444                True                   RESIDENCE   \n",
       "7               24.294444                True             IN_BOND_OR_CAGE   \n",
       "8               22.061111                True                   RESIDENCE   \n",
       "9               31.800000                True                   RESIDENCE   \n",
       "\n",
       "   num_out_for_delivery_attempts  first_attempt_delivery total_events_count  \n",
       "0                              0                    True                 16  \n",
       "1                              0                    True                 18  \n",
       "2                              1                    True                 11  \n",
       "3                              1                    True                 11  \n",
       "4                              1                    True                 17  \n",
       "5                              2                   False                 14  \n",
       "6                              2                   False                 17  \n",
       "7                              0                    True                 12  \n",
       "8                              2                   False                 12  \n",
       "9                              2                   False                 16  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure all required columns exist\n",
    "required_cols = [\n",
    "    \"tracking_number\",\n",
    "    \"service_type\",\n",
    "    \"carrier_code\",\n",
    "    \"package_weight_value\",\n",
    "    \"package_weight_units\",\n",
    "    \"packaging_type\",\n",
    "    \"origin_city\",\n",
    "    \"origin_state\",\n",
    "    \"origin_pincode\",\n",
    "    \"destination_city\",\n",
    "    \"destination_state\",\n",
    "    \"destination_pincode\",\n",
    "    \"pickup_datetime_ist\",\n",
    "    \"delivery_datetime_ist\",\n",
    "    \"total_transit_hours\",\n",
    "    \"num_facilities_visited\",\n",
    "    \"num_in_transit_events\",\n",
    "    \"time_in_inter_facility_transit_hours\",\n",
    "    \"avg_hours_per_facility\",\n",
    "    \"is_express_service\",\n",
    "    \"delivery_location_type\",\n",
    "    \"num_out_for_delivery_attempts\",\n",
    "    \"first_attempt_delivery\",\n",
    "    \"total_events_count\"\n",
    "]\n",
    "\n",
    "# Add missing columns with default placeholders\n",
    "\n",
    "for col in required_cols:\n",
    "    if col not in df_metrics.columns:\n",
    "        if \"city\" in col or \"state\" in col or \"pincode\" in col or \"packaging\" in col:\n",
    "            df_metrics[col] = \"UNKNOWN\"\n",
    "        elif \"num_\" in col or \"hours\" in col or \"weight\" in col:\n",
    "            df_metrics[col] = 0\n",
    "        elif \"is_express\" in col or \"first_attempt\" in col:\n",
    "            df_metrics[col] = False\n",
    "        elif \"datetime\" in col:\n",
    "            df_metrics[col] = pd.NaT\n",
    "        else:\n",
    "            df_metrics[col] = np.nan\n",
    "\n",
    "def convert_to_kg(value, unit):\n",
    "    \"\"\"Convert weight to kilograms if needed.\"\"\"\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return 0.0\n",
    "        if isinstance(value, str):\n",
    "            value = float(value)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "    \n",
    "    unit = (unit or \"\").upper()\n",
    "    if unit in [\"KG\", \"KGS\", \"KILOGRAM\", \"KILOGRAMS\"]:\n",
    "        return round(value, 3)\n",
    "    elif unit in [\"LB\", \"LBS\", \"POUND\", \"POUNDS\"]:\n",
    "        return round(value * 0.453592, 3)\n",
    "    else:\n",
    "        return round(value, 3)  \n",
    "\n",
    "df_metrics[\"package_weight_kg\"] = df_metrics.apply(\n",
    "    lambda x: convert_to_kg(x.get(\"package_weight_value\"), x.get(\"package_weight_units\")), axis=1\n",
    ")\n",
    "\n",
    "def format_ts(ts):\n",
    "    if pd.isna(ts):\n",
    "        return \"\"\n",
    "    try:\n",
    "        ts = pd.to_datetime(ts, errors=\"coerce\")\n",
    "        if pd.isna(ts):\n",
    "            return \"\"\n",
    "        if ts.tzinfo is None:\n",
    "            ts = ts.tz_localize(\"Asia/Kolkata\")\n",
    "        else:\n",
    "            ts = ts.tz_convert(\"Asia/Kolkata\")\n",
    "        return ts.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "df_metrics[\"pickup_datetime_ist_str\"] = df_metrics[\"pickup_datetime_ist\"].apply(format_ts)\n",
    "df_metrics[\"delivery_datetime_ist_str\"] = df_metrics[\"delivery_datetime_ist\"].apply(format_ts)\n",
    "\n",
    "final_cols = [\n",
    "    \"tracking_number\",\n",
    "    \"service_type\",\n",
    "    \"carrier_code\",\n",
    "    \"package_weight_kg\",\n",
    "    \"packaging_type\",\n",
    "    \"origin_city\",\n",
    "    \"origin_state\",\n",
    "    \"origin_pincode\",\n",
    "    \"destination_city\",\n",
    "    \"destination_state\",\n",
    "    \"destination_pincode\",\n",
    "    \"pickup_datetime_ist_str\",\n",
    "    \"delivery_datetime_ist_str\",\n",
    "    \"total_transit_hours\",\n",
    "    \"num_facilities_visited\",\n",
    "    \"num_in_transit_events\",\n",
    "    \"time_in_inter_facility_transit_hours\",\n",
    "    \"avg_hours_per_facility\",\n",
    "    \"is_express_service\",\n",
    "    \"delivery_location_type\",\n",
    "    \"num_out_for_delivery_attempts\",\n",
    "    \"first_attempt_delivery\",\n",
    "    \"total_events_count\"\n",
    "]\n",
    "\n",
    "rename_map = {\n",
    "    \"pickup_datetime_ist_str\": \"pickup_datetime_ist\",\n",
    "    \"delivery_datetime_ist_str\": \"delivery_datetime_ist\"\n",
    "}\n",
    "\n",
    "df_detailed_export = df_metrics[final_cols].rename(columns=rename_map)\n",
    "\n",
    "output_filename = \"transit_performance_detailed.csv\"\n",
    "df_detailed_export.to_csv(output_filename, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Detailed transit performance CSV created successfully!\")\n",
    "print(f\"File Path: {os.path.abspath(output_filename)}\")\n",
    "print(f\"Total Shipments Exported: {len(df_detailed_export)}\")\n",
    "\n",
    "display(df_detailed_export.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161396c",
   "metadata": {},
   "source": [
    "## Part 6: Output Network Performance Summary CSV\n",
    "### Objective:\n",
    "Generate an aggregated summary file \"transit_performance_summary.csv\"\n",
    "covering overall, facility, service-type, and delivery performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1683776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mode, StatisticsError\n",
    "\n",
    "assert 'df_metrics' in globals(), \"df_metrics not found — please run Part 3–5 first.\"\n",
    "\n",
    "df_summary_base = df_metrics.copy()\n",
    "\n",
    "# Drop rows with no tracking_number (safety)\n",
    "df_summary_base = df_summary_base.dropna(subset=[\"tracking_number\"])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Overall Metrics\n",
    "# ----------------------------------------------------------\n",
    "total_shipments = df_summary_base[\"tracking_number\"].nunique()\n",
    "\n",
    "transit_hours = df_summary_base[\"total_transit_hours\"].dropna()\n",
    "avg_transit_hours = round(transit_hours.mean(), 2)\n",
    "median_transit_hours = round(transit_hours.median(), 2)\n",
    "std_dev_transit_hours = round(transit_hours.std(ddof=0), 2)\n",
    "min_transit_hours = round(transit_hours.min(), 2)\n",
    "max_transit_hours = round(transit_hours.max(), 2)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Facility Metrics\n",
    "# ----------------------------------------------------------\n",
    "facilities = df_summary_base[\"num_facilities_visited\"].fillna(0)\n",
    "avg_facilities_per_shipment = round(facilities.mean(), 2)\n",
    "median_facilities_per_shipment = round(facilities.median(), 2)\n",
    "try:\n",
    "    mode_facilities_per_shipment = int(mode(facilities))\n",
    "except StatisticsError:\n",
    "    mode_facilities_per_shipment = np.nan\n",
    "\n",
    "avg_hours_per_facility = round(df_summary_base[\"avg_hours_per_facility\"].dropna().mean(), 2)\n",
    "median_hours_per_facility = round(df_summary_base[\"avg_hours_per_facility\"].dropna().median(), 2)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Service Type Comparison\n",
    "# ----------------------------------------------------------\n",
    "service_group = df_summary_base.groupby(\"service_type\", dropna=False)\n",
    "\n",
    "service_summary = (\n",
    "    service_group.agg(\n",
    "        avg_transit_hours_by_service_type=(\"total_transit_hours\", \"mean\"),\n",
    "        avg_facilities_by_service_type=(\"num_facilities_visited\", \"mean\"),\n",
    "        count_shipments_by_service_type=(\"tracking_number\", \"nunique\"),\n",
    "    )\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Delivery Performance\n",
    "# ----------------------------------------------------------\n",
    "first_attempt_ratio = (\n",
    "    df_summary_base[\"first_attempt_delivery\"].mean() * 100\n",
    "    if \"first_attempt_delivery\" in df_summary_base.columns else 0\n",
    ")\n",
    "avg_out_for_delivery_attempts = (\n",
    "    df_summary_base[\"num_out_for_delivery_attempts\"].mean()\n",
    "    if \"num_out_for_delivery_attempts\" in df_summary_base.columns else 0\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Combine Summary Sections into a Structured Output\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# 1. Overall metrics table\n",
    "overall_summary = pd.DataFrame([{\n",
    "    \"metric\": \"Overall Metrics\",\n",
    "    \"total_shipments_analyzed\": total_shipments,\n",
    "    \"avg_transit_hours\": avg_transit_hours,\n",
    "    \"median_transit_hours\": median_transit_hours,\n",
    "    \"std_dev_transit_hours\": std_dev_transit_hours,\n",
    "    \"min_transit_hours\": min_transit_hours,\n",
    "    \"max_transit_hours\": max_transit_hours\n",
    "}])\n",
    "\n",
    "# 2. Facility metrics table\n",
    "facility_summary = pd.DataFrame([{\n",
    "    \"metric\": \"Facility Metrics\",\n",
    "    \"avg_facilities_per_shipment\": avg_facilities_per_shipment,\n",
    "    \"median_facilities_per_shipment\": median_facilities_per_shipment,\n",
    "    \"mode_facilities_per_shipment\": mode_facilities_per_shipment,\n",
    "    \"avg_hours_per_facility\": avg_hours_per_facility,\n",
    "    \"median_hours_per_facility\": median_hours_per_facility\n",
    "}])\n",
    "\n",
    "# 3. Delivery performance\n",
    "delivery_summary = pd.DataFrame([{\n",
    "    \"metric\": \"Delivery Performance\",\n",
    "    \"pct_first_attempt_delivery\": round(first_attempt_ratio, 2),\n",
    "    \"avg_out_for_delivery_attempts\": round(avg_out_for_delivery_attempts, 2)\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ae7fb",
   "metadata": {},
   "source": [
    "### Export All to a Single CSV and show the summary here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bda52934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network performance summary file created successfully!\n",
      "File Path: C:\\Users\\Alok verma\\Downloads\\transit_performance_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>total_shipments_analyzed</th>\n",
       "      <th>avg_transit_hours</th>\n",
       "      <th>median_transit_hours</th>\n",
       "      <th>std_dev_transit_hours</th>\n",
       "      <th>min_transit_hours</th>\n",
       "      <th>max_transit_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall Metrics</td>\n",
       "      <td>99</td>\n",
       "      <td>94.01</td>\n",
       "      <td>93.25</td>\n",
       "      <td>64.5</td>\n",
       "      <td>15.33</td>\n",
       "      <td>544.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric  total_shipments_analyzed  avg_transit_hours  \\\n",
       "0  Overall Metrics                        99              94.01   \n",
       "\n",
       "   median_transit_hours  std_dev_transit_hours  min_transit_hours  \\\n",
       "0                 93.25                   64.5              15.33   \n",
       "\n",
       "   max_transit_hours  \n",
       "0             544.28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>avg_facilities_per_shipment</th>\n",
       "      <th>median_facilities_per_shipment</th>\n",
       "      <th>mode_facilities_per_shipment</th>\n",
       "      <th>avg_hours_per_facility</th>\n",
       "      <th>median_hours_per_facility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facility Metrics</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>34.04</td>\n",
       "      <td>31.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric  avg_facilities_per_shipment  \\\n",
       "0  Facility Metrics                         2.83   \n",
       "\n",
       "   median_facilities_per_shipment  mode_facilities_per_shipment  \\\n",
       "0                             3.0                             3   \n",
       "\n",
       "   avg_hours_per_facility  median_hours_per_facility  \n",
       "0                   34.04                      31.62  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_type</th>\n",
       "      <th>avg_transit_hours_by_service_type</th>\n",
       "      <th>avg_facilities_by_service_type</th>\n",
       "      <th>count_shipments_by_service_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FEDEX_EXPRESS_SAVER</td>\n",
       "      <td>94.01</td>\n",
       "      <td>2.83</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          service_type  avg_transit_hours_by_service_type  \\\n",
       "0  FEDEX_EXPRESS_SAVER                              94.01   \n",
       "\n",
       "   avg_facilities_by_service_type  count_shipments_by_service_type  \n",
       "0                            2.83                               99  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>pct_first_attempt_delivery</th>\n",
       "      <th>avg_out_for_delivery_attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delivery Performance</td>\n",
       "      <td>84.85</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 metric  pct_first_attempt_delivery  \\\n",
       "0  Delivery Performance                       84.85   \n",
       "\n",
       "   avg_out_for_delivery_attempts  \n",
       "0                           0.97  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To keep both aggregated tables & grouped service-type comparison\n",
    "# we'll concatenate them with labels for clarity.\n",
    "summary_export_path = \"C:/Users/Alok verma/Downloads/transit_performance_summary.csv\"\n",
    "\n",
    "with open(summary_export_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    f.write(\"### OVERALL METRICS ###\\n\")\n",
    "overall_summary.to_csv(summary_export_path, index=False, mode=\"a\", encoding=\"utf-8\")\n",
    "\n",
    "with open(summary_export_path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    f.write(\"\\n### FACILITY METRICS ###\\n\")\n",
    "    facility_summary.to_csv(f, index=False)\n",
    "    f.write(\"\\n### SERVICE TYPE COMPARISON ###\\n\")\n",
    "    service_summary.to_csv(f, index=False)\n",
    "    f.write(\"\\n### DELIVERY PERFORMANCE ###\\n\")\n",
    "    delivery_summary.to_csv(f, index=False)\n",
    "\n",
    "print(f\"Network performance summary file created successfully!\")\n",
    "print(f\"File Path: {os.path.abspath(summary_export_path)}\")\n",
    "\n",
    "# Optional preview of results\n",
    "display(overall_summary)\n",
    "display(facility_summary)\n",
    "display(service_summary)\n",
    "display(delivery_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
